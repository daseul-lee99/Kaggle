{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "* categorical variable은 제한된 값을 사용함\n",
    "    * 얼마나 자주 아침을 먹나요?에 대한 대답으로 \"Never\", \"Rarely\", \"Most days\", \"Every day\"가 있을 때, 이 데이터는 categorical하다고 함\n",
    "    * 당신의 차 브랜드는 무엇인가요?에 대답으로 \"Honda\", \"Toyota\", \"Ford\"가 있을 때, 이 데이터 또한 categorical\n",
    "* 이러한 데이터를 전처리없이 머신 러닝 모델에 사용하려고 하면 에러가 발생함\n",
    "\n",
    "<br>\n",
    "\n",
    "## Three Approaches\n",
    "\n",
    "#### 1. Drop Categorical Variables\n",
    "\n",
    "* 데이터셋에서 categorical variables(컬럼) 제거하기\n",
    "    * categorical variables를 처리하는 가장 쉬운 방법\n",
    "* 컬럼이 유용한 정보를 포함하지 않을 때 사용\n",
    "\n",
    "<br>\n",
    "\n",
    "#### 2. Label Encoding\n",
    "\n",
    "* 고유한 값에 따른 정수 할당하기\n",
    "\n",
    "<img src=\"../images/3/LabelEncoing.png\">\n",
    "\n",
    "* \"Every day\"==3, \"Never\"==0, \"Rarely\"==1, \"Most days\"==2를 할당함\n",
    "* 위의 예제에서는 의미대로 순서를 매겼지만(\"Never\"==0), 모든 categorical variables가 명확한 순서를 갖지는 않음\n",
    "    * but, tree 기반의 모델(ex. decision tree, random forests)은 순서가 있는 label encoding이 더 좋을 수 있음\n",
    "    \n",
    "<br>\n",
    "\n",
    "#### One-Hot Encoding\n",
    "\n",
    "* 원래 데이터의 한 컬럼에 존재하는 카테고리를 이름으로 갖는 새 컬럼 추가하기\n",
    "* 원래 카테고리가 새로 추가된 컬럼에 해당하면 1, 해당하지 않으면 0\n",
    "\n",
    "<img src=\"../images/3/One-HotEncoding.png\">\n",
    "\n",
    "* \"Red\", \"Yellow\", \"Green\" 컬럼을 새롭게 추가하고, 동일한 row에서 Color 컬럼의 데이터가 속하는 컬럼에 1을 할당\n",
    "    * ex. 첫번째 row의 \"Red\"는 새로 추가된 Red 컬럼에서 1이고, 나머지 컬럼에서는 0값을 가짐\n",
    "* label encoding과 대조적으로, one-hot encoding은 카테고리의 순서를 지정하지 않음\n",
    "    * one-hot encoding은 순서가 명확하지 않은 categorical datad에서 잘 작동함(ex. Red는 Yellow 보다 큰 것이 아님)\n",
    "    * 이러한 변수를 **nominal variables**하고 함(명목형 변수)\n",
    "* **일반적으로 한 컬럼에 너무 많은 카테고리(15개 이상)가 있을 때는 수행하지 않음**\n",
    "\n",
    "<br>\n",
    "\n",
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daseul/anaconda2/envs/py36/lib/python3.6/site-packages/pandas/core/frame.py:4117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Method</th>\n",
       "      <th>Regionname</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Bedroom2</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Propertycount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12167</th>\n",
       "      <td>u</td>\n",
       "      <td>S</td>\n",
       "      <td>Southern Metropolitan</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3182.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-37.85984</td>\n",
       "      <td>144.9867</td>\n",
       "      <td>13240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6524</th>\n",
       "      <td>h</td>\n",
       "      <td>SA</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3016.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>-37.85800</td>\n",
       "      <td>144.9005</td>\n",
       "      <td>6380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8413</th>\n",
       "      <td>h</td>\n",
       "      <td>S</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>3</td>\n",
       "      <td>12.6</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>-37.79880</td>\n",
       "      <td>144.8220</td>\n",
       "      <td>3755.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2919</th>\n",
       "      <td>u</td>\n",
       "      <td>SP</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3046.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>-37.70830</td>\n",
       "      <td>144.9158</td>\n",
       "      <td>8870.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043</th>\n",
       "      <td>h</td>\n",
       "      <td>S</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>3</td>\n",
       "      <td>13.3</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>673.0</td>\n",
       "      <td>-37.76230</td>\n",
       "      <td>144.8272</td>\n",
       "      <td>4217.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Type Method             Regionname  Rooms  Distance  Postcode  Bedroom2  \\\n",
       "12167    u      S  Southern Metropolitan      1       5.0    3182.0       1.0   \n",
       "6524     h     SA   Western Metropolitan      2       8.0    3016.0       2.0   \n",
       "8413     h      S   Western Metropolitan      3      12.6    3020.0       3.0   \n",
       "2919     u     SP  Northern Metropolitan      3      13.0    3046.0       3.0   \n",
       "6043     h      S   Western Metropolitan      3      13.3    3020.0       3.0   \n",
       "\n",
       "       Bathroom  Landsize  Lattitude  Longtitude  Propertycount  \n",
       "12167       1.0       0.0  -37.85984    144.9867        13240.0  \n",
       "6524        2.0     193.0  -37.85800    144.9005         6380.0  \n",
       "8413        1.0     555.0  -37.79880    144.8220         3755.0  \n",
       "2919        1.0     265.0  -37.70830    144.9158         8870.0  \n",
       "6043        1.0     673.0  -37.76230    144.8272         4217.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the data\n",
    "data = pd.read_csv('../input/melb_data.csv')\n",
    "\n",
    "# Separate target from predictors\n",
    "y = data.Price\n",
    "X = data.drop(['Price'], axis=1)\n",
    "\n",
    "# Divide data into training and validation subsets\n",
    "X_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
    "                                                                random_state=0)\n",
    "\n",
    "# Drop columns with missing values (simplest approach)\n",
    "cols_with_missing = [col for col in X_train_full.columns if X_train_full[col].isnull().any()] \n",
    "X_train_full.drop(cols_with_missing, axis=1, inplace=True)\n",
    "X_valid_full.drop(cols_with_missing, axis=1, inplace=True)\n",
    "\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "low_cardinality_cols = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() < 10 and \n",
    "                        X_train_full[cname].dtype == \"object\"]\n",
    "\n",
    "# Select numerical columns\n",
    "numerical_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Keep selected columns only\n",
    "my_cols = low_cardinality_cols + numerical_cols\n",
    "X_train = X_train_full[my_cols].copy()\n",
    "X_valid = X_valid_full[my_cols].copy()\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "* 학습 데이터에서 모든 categorical variables 얻기\n",
    "* 컬럼이 `object` 타입(dtype)이라는 것은 컬럼이 text data를 포함하고 있다는 것을 나타냄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical variables:\n",
      "['Type', 'Method', 'Regionname']\n"
     ]
    }
   ],
   "source": [
    "## Get list of categorical variables ##\n",
    "s = (X_train.dtypes == 'object')\n",
    "object_cols = list(s[s].index)\n",
    "\n",
    "print(\"Categorical variables:\")\n",
    "print(object_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Define Function to Measure Quality of Each Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "## Function for comparing different approaches ##\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    \n",
    "    return mean_absolute_error(y_valid, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Score from Approach 1 (Drop Categorical Variables)\n",
    "\n",
    "* `select_dtypes()`를 사용해 `object` 컬럼을 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 1 (Dro pcategorical variables): \n",
      "175703.48185157913\n"
     ]
    }
   ],
   "source": [
    "drop_X_train = X_train.select_dtypes(exclude=['object'])\n",
    "drop_X_valid = X_valid.select_dtypes(exclude=['object'])\n",
    "\n",
    "print(\"MAE from Approach 1 (Dro pcategorical variables): \")\n",
    "print(score_dataset(drop_X_train, drop_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score from Approach 2 (Label Encoding)\n",
    "\n",
    "* scikit-learn의 class `LabelEncoder`\n",
    "* 각 컬럼별로 label encoding 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 2 (Label Encoding): \n",
      "165936.40548390493\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "## Make copy to avoid changning original data ##\n",
    "label_X_train = X_train.copy()\n",
    "label_X_valid = X_valid.copy()\n",
    "\n",
    "## Apply label encoder to each column with categorical data ##\n",
    "label_encoder = LabelEncoder()\n",
    "for col in object_cols:\n",
    "    label_X_train[col] = label_encoder.fit_transform(X_train[col])\n",
    "    label_X_valid[col] = label_encoder.transform(X_valid[col])\n",
    "    \n",
    "print(\"MAE from Approach 2 (Label Encoding): \")\n",
    "print(score_dataset(label_X_train, label_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 한 컬럼내의 각 카테고리에 랜덤하게 값 부여\n",
    "* 간단하게 값을 부여할 수도 있지만, 더 좋은 성능을 얻기 위해 더 나은(유용한) 값을 부여할 수 있음\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Score from Approach 3 (One-Hot Encoding)\n",
    "\n",
    "* scikit-learn이 class `OneHotEncoder`\n",
    "* 이 동작을 커스터마이즈할 수 있게 하는 수 많은 파라미터가 있음\n",
    "    * `handle_unknown='ignore'`: default='error'. validation data가 training data에서 나타나지 않은 클래스를 포함할 때 에러를 무시\n",
    "        transform을 수행하는 동안 알수없는 카테고리를 만나면, 해당 값에 대한 one-hot encoding 결과는 0이 됨(inverse transform하면 None)\n",
    "    * `sparse=False`: default=True. encoding된 컬럼을 sparse matrix(희소행렬. 대부분의 값이 0인 행렬) 대신 numpy array로 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 3 (One-Hot Encoding): \n",
      "166089.4893009678\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "## Apply one-hot encoder to each column with categorical data ##\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[object_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[object_cols]))\n",
    "\n",
    "## One-hot encoding removed index; put it back ##\n",
    "OH_cols_train.index = X_train.index\n",
    "OH_cols_valid.index = X_valid.index\n",
    "\n",
    "## Remove categorical columns (will replace with one-hot encoding) ##\n",
    "num_X_train = X_train.drop(object_cols, axis=1)\n",
    "num_X_valid = X_valid.drop(object_cols, axis=1)\n",
    "\n",
    "## Add one-hot encoded columns to numerical features ##\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
    "\n",
    "print(\"MAE from Approach 3 (One-Hot Encoding): \")\n",
    "print(score_dataset(OH_X_train, OH_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Which approach is best?\n",
    "\n",
    "* 이 경우에선 컬럼을 전부 제거(Approach 1)하는 방법의 성능이 가장 좋지 않음\n",
    "* 나머지 두 방법은 error가 비슷(의미 있는 장점 X)\n",
    "* 일반적으로는 one-hot encoding(Approach 3)이 가장 좋은 성능을 내고, 컬럼을 전부 제거하는 방법의 성능이 가장 좋지 않음(경우에 따라 다르기도 함)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
