{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "* 깊이가 깊은 tree는 overfitting을 야기함\n",
    "    * 너무 적은 데이터로 학습된 상태에서 예측을 해야하기 때문\n",
    "* 깊이가 얕은 tree는 underfitting을 야기함\n",
    "    * 너무 많은(광범위한) 데이터로 인해 데이터의 패턴을 잡아내지 못하기 때문\n",
    "* 정교한 모델링 기술들도 overfitting과 underfitting 문제를 겪고 있음\n",
    "* But 많은 모델들이 더 좋은 성능을 끌어내는 아이디어를 가지고 있음\n",
    "\n",
    "<br>\n",
    "\n",
    "* Random Forests: 수 많은 tree를 사용하는 모델\n",
    "    * 각 tree의 예측 결과를 평균내어 최종 예측을 함\n",
    "    * 일반적으로 single decision tree보다 더 좋은 예측 정확도를 보임\n",
    "    * 기본 파라미터(default parameters)로 잘 작동함\n",
    "        * 많은 모델들이 정확한(좋은 성능을 위한) 파라미터를 얻는 데 민감함(얻기 어려움)\n",
    "\n",
    "<br><br>\n",
    "\n",
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "    \n",
    "## Load data ##\n",
    "melbourne_file_path = '../input/melb_data.csv'\n",
    "melbourne_data = pd.read_csv(melbourne_file_path) \n",
    "\n",
    "## Filter rows with missing values ##\n",
    "melbourne_data = melbourne_data.dropna(axis=0)\n",
    "\n",
    "## Choose target and features ##\n",
    "y = melbourne_data.Price\n",
    "melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea', \n",
    "                        'YearBuilt', 'Lattitude', 'Longtitude']\n",
    "X = melbourne_data[melbourne_features]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202888.18157951365\n"
     ]
    }
   ],
   "source": [
    "## to remove sklearn warning ##\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "forest_model = RandomForestRegressor(random_state=1)\n",
    "forest_model.fit(train_X, train_y)\n",
    "melb_preds = forest_model.predict(val_X)\n",
    "print(mean_absolute_error(val_y, melb_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "* 더 개선할 여지가 있지만, 앞에서 했던 best decision tree의 error 250,000보다 크게 나아짐\n",
    "* 앞에서 tree의 깊이를 조절했던 것처럼 random forests의 파라미터를 조절할 수도 있지만, random forests 모델의 가장 좋은 특징 중 하나는 별도의 파라미터 튜닝 없이도 알아서 잘 동작한다는 것\n",
    "\n",
    "<br>\n",
    "\n",
    "* 곧 배우게 될 XGBoost 모델은 파라미터가 올바르게 튜닝되었을 때 더 좋은 성능을 냄(파라미터를 튜닝하는 스킬이 필요)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
